{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to train your Keypoint Moseq Model:\n",
    "Ok... so you are going to have to bare with me because this tutorial involves ***a lot*** of jumping back and forth. \n",
    "\n",
    "## There are a few steps to training the Keypoint Moseq Model:\n",
    "### **1. Calibration and PCA (JupyterLab)**\n",
    "- Essentially you have to set it up so the Keypoint Moseq model can know how accurate the SLEAP model is\n",
    "- The calibration part is interactive you will have to do that in Jupyterlab\n",
    "- You will also set up your kappa for step **2. Fitting AR-HMM Model**, which is just the distribution of syllable lengths. Higher kappa, longer syllables. \n",
    "### **2. Fitting AR-HMM Model (notebook or Python Script on HPC)**\n",
    "- AR-HMM: Autoreggressive Hidden Markov Model (no, I don't know what that is)\n",
    "- This step can also take awhile so you can also run this model fitting as a script on the HPC. I include it in the notebook because when I tried it in a notebook, it didn't crash my kernel like step **3. Fitting a Full Model** did and for me, it's easier to keep track of the order of things in a Jupyter Notebook.\n",
    "### **3. Fitting a Full Model (Python Script on HPC)**\n",
    "- This is the Jupyter kernel killer step so you have to run it as a script on the HPC. I will include the name and order of which scripts to run once you get to this point in the notebook. Don't worry, Mommy is going to hold your hand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First you need to import your Keypoint Moseq package:\n",
    "Since you need to do step **1. Calibration and PCA** in JupyterLab anyways you might as well start running this code there. To open Ju"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keypoint_moseq as kpms\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### and also set up filepaths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sleap_model_path = 'C:/Users/Steve/Desktop/Karin/tutorials/240709_092906.multi_instance.n=1301/' #CHANGE HERE where is your SLEAP model?\n",
    "project_dir = r'Y:\\Karin\\tutorialmaking\\newkatiesvideomodeling' #CHANGE HERE\n",
    "video_dir = os.path.join(project_dir, 'videos')\n",
    "data_dir = video_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### aaand set up your config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = lambda: kpms.load_config(project_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bodyparts=[\n",
    "'nose',\n",
    "'earL',\n",
    "'earR',\n",
    "'head',\n",
    "'centroid',\n",
    "'tailBase',\n",
    "'tailEnd',\n",
    "'upperBack',\n",
    "'lowerBack',\n",
    "'lateralL',\n",
    "'lateralR',]\n",
    "\n",
    "skeleton=[\n",
    "    ['nose', 'earL'],\n",
    "    ['nose', 'earR'],\n",
    "    ['nose', 'head'],\n",
    "    ['nose', 'lateralL'],\n",
    "    ['nose', 'lateralR'],\n",
    "    ['head', 'upperBack'],\n",
    "    ['upperBack', 'lowerBack'],\n",
    "    ['lowerBack', 'tailBase'],\n",
    "    ['tailBase', 'tailEnd']\n",
    "    ]\n",
    "kpms.setup_project(\n",
    "    project_dir,\n",
    "    video_dir=video_dir,\n",
    "    bodyparts=bodyparts,\n",
    "    skeleton=skeleton,\n",
    "    overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kpms.update_config(\n",
    "    project_dir,\n",
    "    video_dir=video_dir,\n",
    "    anterior_bodyparts=['nose'],\n",
    "    posterior_bodyparts=['tailBase'],\n",
    "    use_bodyparts=[\n",
    "   'nose','earL', 'earR','head','centroid','tailBase','upperBack','lowerBack'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now load your coordinate data.\n",
    "I wrote this code so it will open .h5 files, though you can change the code so it can use .slp data. If you want to use DeepLabCuts output, you will have to change the code also, but I don't feel like going in to instructions for DeepLabCuts-Keypoint Moseq work so just look at the [Keypoint Moseq Colab notebook](https://colab.research.google.com/github/dattalab/keypoint-moseq/blob/main/docs/keypoint_moseq_colab.ipynb) from the developers for reference if you really want (also you can look for reference if you want to get rid of the \"only being able to use .h5 files\" part of my code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure 'videos' directory within data_dir\n",
    "keypoint_data_path = os.path.join(project_dir, 'videos')\n",
    "\n",
    "# Load only files ending with .h5\n",
    "h5_files = [f for f in os.listdir(keypoint_data_path) if f.endswith('.h5')]\n",
    "\n",
    "# Assuming kpms.load_keypoints and kpms.format_data are functions provided by a library\n",
    "coordinates, confidences, bodyparts = kpms.load_keypoints([os.path.join(keypoint_data_path, f) for f in h5_files], 'sleap')\n",
    "\n",
    "# format data for modeling\n",
    "data, metadata = kpms.format_data(coordinates, confidences, **config())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Calibration and PCA (JupyterLab)\n",
    "So you should be in JupyterLab, if you are not, open this notebook in JupyterLab. You need JupyterLab to calibrate the SLEAP model with Keypoint Moseq interactively.\n",
    "So taken directly from the [Keypoint Moseq Colab notebook](https://colab.research.google.com/github/dattalab/keypoint-moseq/blob/main/docs/keypoint_moseq_colab.ipynb) from the developers, here are the calibration instructions:\n",
    "\n",
    "##### Run the cell below. A widget should appear with a video frame on the left.\n",
    "##### Annotate each frame with the correct location of the labeled bodypart\n",
    "- ##### Left click to specify the correct location - an “X” should appear.\n",
    "- ##### Use the arrow buttons to annotate additional frames.\n",
    "- ##### Each annotation adds a point to the right-hand scatter plot.\n",
    "- ##### Continue until the regression line stabilizes.\n",
    "##### At any point, adjust the confidence threshold by clicking on the scatter plot.\n",
    "##### Use the “save” button to update the config and store your annotations to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kpms.noise_calibration(project_dir, coordinates, confidences, **config())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit the PCA\n",
    "You will also have to fit a PCA to your calibration data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = kpms.fit_pca(**data, **config())\n",
    "kpms.save_pca(pca, project_dir)\n",
    "\n",
    "kpms.print_dims_to_explain_variance(pca, 0.9)\n",
    "kpms.plot_scree(pca, project_dir=project_dir)\n",
    "kpms.plot_pcs(pca, project_dir=project_dir, **config())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Change your ```latent_dim``` to however many dimensions are needed to explain 90% of the variance (take from previous cell output) or 10 dimensions, whichever is lower:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kpms.update_config(project_dir, latent_dim=2) #CHANGE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Fitting AR-HMM Model (notebook or Python Script on HPC)\n",
    "This step can take a while so it may be better to run the `arhmmfit.py` script from the repository on the HPC. This will save a model and in the future, you will use the name of the folder (which should be named a date like `2024_07_12-11_12_32` for example) as the `kpmsmodel_name`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up initialize the model and set up `kappa` hyperparameter for the AR-HMM\n",
    "You want to set your kappa to the point where your median syllable durations are about 12 frames. This can take some adjusting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the following to load an already fit model\n",
    "# pca = kpms.load_pca(project_dir)\n",
    "\n",
    "# initialize the model\n",
    "model = kpms.init_model(data, pca=pca, **config())\n",
    "\n",
    "# optionally modify kappa\n",
    "model = kpms.update_hypparams(model, kappa=1e7) #CHANGE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit your AR-HMM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_ar_iters = 50\n",
    "\n",
    "model, kpmsmodel_name = kpms.fit_model(\n",
    "    model, data, metadata, project_dir,\n",
    "    ar_only=True, num_iters=num_ar_iters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Fitting a Full Model (Python Script on HPC)\n",
    "\n",
    "You will have to use the `kpmsmodelfit.py` and `kpmsreindexandsave.py` scripts in order to fit a full model. In this script, you can just fill in the filepaths and you should be good. To run this script you must have HPC access. You have to change the `.py` file in `sample-job.sh` to whichever script you need to run and i ran the script by submiting a job with `sample-job.sh` on to the HPC. You might need to write your own `sample-job.sh` file. This may take some troubleshooting. \n",
    "\n",
    "The `kpmsmodelfit.py` will fit your full Keypoint Moseq model and `kpmsreindexandsave.py` will reindex your syllables by frequency and save them as `results.h5`. You can also adjust the `kappa` for the full model so the median syllable duration is 12 frames. The full model will likely need a lower `kappa`.  \n",
    "\n",
    "\n",
    "#### Once you have a Keypoint Moseq Model you can check here to see what the median frame durations are for every 25 iterations, just put the foldername of the keypoint moseq model of interest in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kpmsmodel_name = 'my_kappa_scanfull550-100.0' #CHANGE HERE\n",
    "\n",
    "import os\n",
    "import keypoint_moseq as kpms\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "checkpoint_path = os.path.join(project_dir, kpmsmodel_name, \"checkpoint\" + \".h5\")\n",
    "\n",
    "with h5py.File(checkpoint_path, \"r\") as f:\n",
    "    saved_iterations = np.sort([int(i) for i in f[\"model_snapshots\"]])\n",
    "    mask = f[\"data/mask\"][()]\n",
    "\n",
    "median_durations = []\n",
    "for i in saved_iterations:\n",
    "    with h5py.File(checkpoint_path, \"r\") as f:\n",
    "        z = np.array(f[f\"model_snapshots/{i}/states/z\"])\n",
    "        median_durations.append(np.median(kpms.get_durations(z, mask)))\n",
    "\n",
    "print(median_durations)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
