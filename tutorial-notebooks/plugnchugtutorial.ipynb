{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Plug-and-Chug Notebook for Getting Your Keypoint Moseq syllable-at-a-frame CSV file and Visualizations:\n",
    "## This notebook includes:\n",
    "   ### **1. Re-encoding videos**\n",
    "   ### **2. Creating inferences (label) on your videos using an existing SLEAP model and exporting the coordinates in an .h5 file**\n",
    "   - you can also do the inferences and exporting the coordinates in the SLEAP application. When running the inferences in the SLEAP app, depending on if and what error message you get, you may need to **re-encode your videos** \n",
    "   ### **3. Getting Behavioral Syllables**\n",
    "   before this step you will have to go to [kpmsmodelmakingtutorial.ipynb](tutorial-notebooks/kpmsmodelmakingtutorial.ipynb) if you do not already have a Keypoint Model trained and the `checkpoint.h5` from that training\n",
    "   - ##### a. Getting ```results.h5``` from your ```checkpoint.h5```\n",
    "   - ##### b. Trajectory plots, grid movies, and other visualizations of your behavioral syllables\n",
    "   - ##### c. ```.csv``` files for analysis\n",
    "\n",
    "\n",
    "\n",
    "This notebook does not include:\n",
    "   - how to create and train a SLEAP model\n",
    "   - how to create and train a Keypoint Moseq model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's get your packages imported so we can use them in our code. A list of packages that you need to install in your environment is in the README.md file. Remember **importing =/= installing** (I've made this silly mistake multiple times when sleep deprived)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess #this is how you are going to use FFmpeg. also, installation of the FFmpeg \"package\" is different from other packages\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Set up filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beforereencodingvidfolder_dir = r'C:\\Users\\Steve\\Desktop\\steve_sleap_test\\beforereencode' #CHANGE HERE to put videos needed to reencode put None if you don't want to reencode\n",
    "project_dir = r'C:\\Users\\Steve\\Desktop\\steve_sleap_test' #CHANGE HERE\n",
    "sleap_model_path = r'Y:\\Karin\\tutorialmaking\\morekatiesvideosmodeling\\sleapstuff\\240709_092906.multi_instance.n=1301' #CHANGE HERE where is your SLEAP model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Just setting this up here, but in order for this next cell to work, you need to put your videos (if they are already reencoded or do not need to be reencoded) **in a folder called `videos` within your project directory**\n",
    "- your `.h5` labels from SLEAP will end up in the `videos` folder. \n",
    "- this cell sets the directory of `videos` in your `project_dir` and creates a folder called `videos` if it does not exist.\n",
    "- if your videos need to be reencoded, just put them in a different folder within your `project_dir` and set your `beforereencodingvidfolder_dir` to that folderpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_dir = os.path.join(project_dir, 'videos')\n",
    "if not os.path.exists(video_dir):\n",
    "    os.makedirs(video_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Re-encoding videos\n",
    "A common problem with SLEAP are videos that are [not reliably seekable](https://sleap.ai/develop/help.html). In my experience, sometimes when I want to run inferences, SLEAP will print out an error in the error log saying something about an issue with the last frame of the video. I've had this issue with a few videos on the Grid (but somehow not Katie's) and it has to do with how the video data is stored (I'm pretty sure). I have also had issues using Keypoint Moseq where it tells me there is some trouble with a given frame in a video. One of the things you can to trouble shoot is re-encoding. Something to note is that re-encoding ***changes your file***, and \n",
    "\n",
    "Anyways, here is a function that will reencode your videos in the ```beforereencodingvidfolder_dir``` folder directory and put them in your `video_dir`\n",
    "\n",
    "You need to run this code in an environment with os and subprocess.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reencode_videos(beforereencodingvidfolder_dir, video_dir):\n",
    "    if beforereencodingvidfolder_dir is None or not os.path.exists(beforereencodingvidfolder_dir):\n",
    "        print('no reencoding today!')\n",
    "        return\n",
    "    else:\n",
    "        # Ensure output directory exists\n",
    "        os.makedirs(video_dir, exist_ok=True)\n",
    "\n",
    "        # FFmpeg command template\n",
    "        ffmpeg_command = 'ffmpeg -y -i \"{input_file}\" -c:v libx264 -pix_fmt yuv420p -preset superfast -crf 23 \"{output_file}\"'\n",
    "\n",
    "        # Iterate through each file in beforevidfolder_dir\n",
    "        for filename in os.listdir(beforereencodingvidfolder_dir):\n",
    "            input_file = os.path.join(beforereencodingvidfolder_dir, filename)\n",
    "            output_file = os.path.join(video_dir, filename)\n",
    "            \n",
    "            # Construct and execute FFmpeg command\n",
    "            command = ffmpeg_command.format(input_file=input_file, output_file=output_file)\n",
    "            \n",
    "            try:\n",
    "                subprocess.run(command, shell=True, check=True)\n",
    "                print(f'Reencoded {filename} and saved as {os.path.basename(output_file)}')\n",
    "            except subprocess.CalledProcessError as e:\n",
    "                print(f'Error reencoding {filename}: {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the code to execute said function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reencode_videos(beforereencodingvidfolder_dir, video_dir)\n"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAH0AAAAgCAYAAAA/kHcMAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAAAPOSURBVGhD7Zk/aBpRHMe/ljbLQUChloCQ6OISF8ExDbRLB7kUpNClioNDhwYhDqHOlgwGxA4dMljtEigHzZGhSwuJo+Biht5SM2SphQwBpw7te3fP8854pzGnvfbeBx7e+5Pz531/v9/7vYtvdXX1Nzie4g775HgILroH4aJ7EC66B+GiexDHq/fQizLKT8O4x/pmfqH7qYDChwvW5/wNHBd9Y7eBHA6Q3muykSF2c5zFMbf0TgWWJElvjd0NNjNvMihLDRQ3Wfd/ZLOIhlQmv3Q25iZ6cy+NVCqlt1mjO7M/dBxpQWLS77R20g0Ua2Y7NAf/dxzN1YUcffgi5KHzVBUgwibdQraMfKIHOZVG6YSNuZy77NO1dM/q7IpwUjI9WNUp1rTrfqtimU2s19GozSO+rPX6rc9Qok+0/lqeRO8WEbMAgwVmaJpN4toaq++j449/ttFLxBG+aqPyHsht+/HlGBCTYXWN2T66VYlgM2hXnXEsV0d6/ayLcHJ82qQpdZgFKkSsPMpZNmnAep0meFSpsDkZCr6hlE1BPtcefspO8AgRfDsKpWpeM8kuIeFHh85lS9CkDUNc72jrq20gkWO/l9onAsf0PnROQXR79n3ciLvP6bUC+7Gj+3kGWwmgLQ8edxOnSh/BB6P7sM26zYeIoo0DParqKFlkiusIiCfjQOtgJPIm29VvHY04UhfyDhs5OYVyJcBPt7DsFuLEvqOaNqXNBRFyoG5wf/VOUnpa93TJEDXkwavOoLV8QoBwf9yGb7Eu4odwecGi7abQVCuTND0uu0xr1ziauLhkl5TlOPLsPpJEtyHmELfE9dW7DhX/mKT79UGCIxFiuL/aBhFjwmZdIESS6KzUUSDpOJg0OiJlWrum4NxQxLJWGET+LXBM9EFkU8829gdtEOkCiQ5j3xqyp+0XTaJk1rWShj7wzjnZC/cn7XA262oddEkk5XQ7MijeNBtRR1SFH2w909o1BdS+NXFMJrk9DokeQiy0BOUwhUqrr45YRbpaIB0qWArFyF/Z0UTpzG9Ib+z4xqKmvlNBOyDqc1bnZOt1JFJJ8UZTtDYuwv9Ds7Eu04KKjk9ROKkZqKemdCrQtHZNZphJ9HvVzEEwK868hhXI0aIWQydbwPdXDT3ax6EeSd5G9PV1zUc4C8QZ0Z+9weGjHkovK+iwIXtiyL8rIvj1OV5/ZEOcheGI6HT/totuK8wvIjiLwvH/snHcj7tfznDmAhfdg3DRPQgX3YP4AoEAL+Q8hi8YDHLRPYZvZWWFi+4x+Dndg/BCzoNw0T0H8AfLIPNkDORkHQAAAABJRU5ErkJggg=="
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Creating inferences (A.K.A. labeling) on your videos using an existing SLEAP model and exporting the 2D coordinates in an .h5 file\n",
    "At this point you are going to have to change the kernel to \"sleap\" (whomp whomp) because for some reason I can't do it for you. Believe me, I tried for like an hour. Basically, I couldn't install Keypoint Moseq in the same environment as SLEAP which is why you need to change kernels.\n",
    "\n",
    "*Anyways*... I wrote a few lines that will run in the terminal to basically generate labels in an .slp file (SLEAP file) and an .h5 file based off of the model that you set 'sleap_model_path' to earlier. The .h5 file is what you will use for classifying the behaviors in your videos. \n",
    "\n",
    "You change kernels by clicking \"select kernel\" in the top right corner ![image.png](attachment:image.png) and you will get a drop down menu on the top-middle part of the ribbon. Select the one named \"sleap\" (or the one with the sleap library in it).\n",
    "##### TLDR: If you started running this notebook in a different kernel, now is the time to ***change your kernel to sleap***. Also, since changing kernels will reset your variables, ***re-run the cell where you imported your packages and the cell where you specified your file/folder paths***\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this first cell is for SLEAP labeling your videos and producing a .slp file for every video to be labeled (yes it will take awhile)\n",
    "\n",
    "This will create a folder named `slp_files` within your project directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slp_output_dir = os.path.join(project_dir, 'slp_files') \n",
    "if not os.path.exists(slp_output_dir): # Create 'slp files' directory if it does not exist\n",
    "    os.makedirs(slp_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_tracks = 1 #number of animals you are tracking\n",
    "tracker = 'simplemaxtracks'\n",
    "for filename in os.listdir(video_dir):\n",
    "    if filename.endswith('.mp4'):\n",
    "        input_file = os.path.join(video_dir, filename)\n",
    "        output_filename = os.path.splitext(filename)[0] + '.slp'\n",
    "        output_file_path = os.path.join(slp_output_dir, output_filename)\n",
    "        sleap_track_command = f\"sleap-track -m {sleap_model_path} \" \\\n",
    "                              f\"--tracking.tracker {tracker} \" \\\n",
    "                              f\"--tracking.max_tracking {1} \" \\\n",
    "                              f\"--tracking.max_tracks {max_tracks} \" \\\n",
    "                              f\"-o {output_file_path} \" \\\n",
    "                              f\"{input_file}\"\n",
    "        try:\n",
    "                # Execute the command\n",
    "                subprocess.run(sleap_track_command, shell=True, check=True)\n",
    "                print(f'labeled {filename} and saved as {output_filename}')\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f'Error processing {filename}: {e}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next cell will convert the .slp files to .h5 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(slp_output_dir):\n",
    "    if filename.endswith('.slp'):\n",
    "        input_slpfile = os.path.join(slp_output_dir, filename)\n",
    "        output_h5filename = os.path.splitext(filename)[0] + '.h5'\n",
    "        output_h5file_path = os.path.join(video_dir, output_h5filename)\n",
    "        sleap_convert_command = f\"sleap-convert --format analysis -o {output_h5file_path} {input_slpfile}\"\n",
    "        try:\n",
    "            subprocess.run(sleap_convert_command)\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f'Error processing {filename}: {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Getting Behavioral Syllables\n",
    "By this point, you should have either a Keypoint Moseq model ready or have trained a Keypoint Moseq model in the [kpmsmodelmakingtutorial.ipynb](tutorial-notebooks/kpmsmodelmakingtutorial.ipynb)\n",
    "\n",
    "You have to change your kernel again (whomp whomp) to the one with the keypoint moseq library installed. This means you will also have to run your filepaths again (from the cell at the beginning) and import your packages (from the cell below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess #this is how you are going to use FFmpeg. also, installation of the FFmpeg \"package\" is different from other packages\n",
    "import keypoint_moseq as kpms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kpmsmodel_name = 'my_kappa_scanfull550-100.0' #CHANGE HERE what is the name of your keypoint moseq model? (not the file path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will just list all of the .h5 files in your `project_dir/videos/` folder\n",
    "- in the online [Keypoint Moseq Colab notebook](https://colab.research.google.com/github/dattalab/keypoint-moseq/blob/main/docs/keypoint_moseq_colab.ipynb) from the developers, they have the `videos` folder also have the .h5 labels as well so that is what I am doing here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir(video_dir):\n",
    "    if filename.endswith('.mp4'):\n",
    "        print(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### If you want to print out a list of videos files with the suffix `.mat` so you can make a list to put in to the MATLAB analysis, here you go:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over files in the directory\n",
    "for filename in os.listdir(video_dir):\n",
    "    # Check if the file has an .mp4 extension\n",
    "    if filename.endswith('.mp4'):\n",
    "        # Remove the .mp4 suffix\n",
    "        name_without_suffix = filename[:-4]\n",
    "        # Print the filename without the .mp4 suffix\n",
    "        print(name_without_suffix+'.mat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3a. Getting results.h5 from your checkpoint.h5\n",
    "So you do need to save your most recent checkpoint as `results.h5`. This code block will also reindex your syllables. Do not run this cell over an existing `results.h5` that you want to keep. it will rewrite it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the most recent model checkpoint\n",
    "model, data, metadata, current_iter = kpms.load_checkpoint(project_dir, kpmsmodel_name)\n",
    "\n",
    "\n",
    "# modify a saved checkpoint so syllables are ordered by frequency\n",
    "kpms.reindex_syllables_in_checkpoint(project_dir, kpmsmodel_name)\n",
    "\n",
    "# extract results\n",
    "results = kpms.extract_results(model, metadata, project_dir, kpmsmodel_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Also load your keypoints from your .h5 files\n",
    "Just so they can be used in your visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure 'videos' directory within data_dir\n",
    "keypoint_data_path = os.path.join(project_dir, 'videos')\n",
    "\n",
    "# Load only files ending with .h5\n",
    "h5_files = [f for f in os.listdir(keypoint_data_path) if f.endswith('.h5')]\n",
    "\n",
    "# Assuming kpms.load_keypoints and kpms.format_data are functions provided by a library\n",
    "coordinates, confidences, bodyparts = kpms.load_keypoints([os.path.join(keypoint_data_path, f) for f in h5_files], 'sleap')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3b. Trajectory plots, grid movies, and other visualizations of your behavioral syllables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = kpms.load_results(project_dir, kpmsmodel_name)\n",
    "config = lambda: kpms.load_config(project_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Make Trajectory Plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kpms.generate_trajectory_plots(coordinates, results, project_dir, kpmsmodel_name, min_frequency=.001, **config()) #you can take out the min_frequency argument if you want to do the default, you can change it to a lower number if you want to see more syllables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Generate Grid Movies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kpms.generate_grid_movies(results, project_dir, kpmsmodel_name, coordinates=coordinates, dot_radius=10, dot_color=(0, 255, 0), min_frequency=.001,overlay_keypoints=True, **config());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create Syllable Dendrogram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kpms.plot_similarity_dendrogram(coordinates, results, project_dir, kpmsmodel_name, **config())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. .csv files for analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to sort your videos by mutant animal and wild-type you can do it here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kpms.interactive_group_setting(project_dir, kpmsmodel_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### to get a table that tells you **when an animal is doing a particular syllable at each frame**, you can do that here\n",
    "also i'm pretty sure when onset is true, that indicates that it is the frame that a behavior starts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moseq_df = kpms.compute_moseq_df(project_dir, kpmsmodel_name, smooth_heading=True) \n",
    "moseq_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and now to save it as a .csv file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save moseq_df\n",
    "save_dir = os.path.join(project_dir, kpmsmodel_name) # directory to save the moseq_df dataframe\n",
    "moseq_df.to_csv(os.path.join(save_dir, 'moseq_df.csv'), index=False)\n",
    "print('Saved `moseq_df` dataframe to', save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os  # Import the os module to use os.path.join\n",
    "\n",
    "# Specify the directory where the CSV file is located\n",
    "save_dir = os.path.join(project_dir, kpmsmodel_name)\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(os.path.join(save_dir, 'moseq_df.csv'))\n",
    "\n",
    "# Replace False with empty strings\n",
    "df.replace(False, '', inplace=True)\n",
    "\n",
    "# Write the modified DataFrame to a new CSV file\n",
    "df.to_csv(os.path.join(save_dir, 'modifiedmoseqdf.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this can give you some information about the syllables i'm pretty sure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_df = kpms.compute_stats_df(\n",
    "    project_dir,\n",
    "    kpmsmodel_name,\n",
    "    moseq_df, \n",
    "    min_frequency=0.005,       # threshold frequency for including a syllable in the dataframe\n",
    "    groupby=['group', 'name'], # column(s) to group the dataframe by\n",
    "    fps=30)                    # frame rate of the video from which keypoints were inferred\n",
    "\n",
    "stats_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "aaaand you can also save it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save stats_df\n",
    "save_dir = os.path.join(project_dir, kpmsmodel_name)\n",
    "stats_df.to_csv(os.path.join(save_dir, 'stats_df'), index=False)\n",
    "print('Saved `stats_df` dataframe to', save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Here is where you will **label your syllables**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kpms.label_syllables(project_dir, kpmsmodel_name, moseq_df) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Heatmap to show you **transition frequencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize='bigram' # normalization method (\"bigram\", \"rows\" or \"columns\")\n",
    "\n",
    "trans_mats, usages, groups, syll_include=kpms.generate_transition_matrices(\n",
    "    project_dir, kpmsmodel_name, normalize=normalize,\n",
    "    min_frequency=0.005 # minimum syllable frequency to include\n",
    ")    \n",
    "\n",
    "kpms.visualize_transition_bigram(\n",
    "    project_dir, kpmsmodel_name, groups, trans_mats, syll_include, normalize=normalize, \n",
    "    show_syllable_names=False )# label syllables by index (False) or index and name (True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Syllable Transition Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a transition graph for each single group\n",
    "\n",
    "kpms.plot_transition_graph_group(\n",
    "    project_dir, kpmsmodel_name, \n",
    "    groups, trans_mats, usages, syll_include, \n",
    "    layout='circular',        # transition graph layout (\"circular\" or \"spring\")\n",
    "    show_syllable_names=False) # label syllables by index (False) or index and name (True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Generate a difference graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a difference-graph for each pair of groups.\n",
    "\n",
    "kpms.plot_transition_graph_difference(project_dir, kpmsmodel_name, \n",
    "                                      groups, trans_mats, usages, syll_include, \n",
    "                                      layout='circular') # transition graph layout (\"circular\" or \"spring\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
